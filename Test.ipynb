{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83f4eaa6-a6b8-4b2c-98b9-db8b51ed5351",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1741142918.510849  177519 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1741142918.514302  177519 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "I0000 00:00:1741142920.399175  177519 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3583 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 6GB Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "/home/natan/.pyenv/versions/3.10.16/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "\n",
    "from scipy.special import comb, loggamma, lambertw\n",
    "from scipy.stats import multinomial, expon\n",
    "\n",
    "from silence_tensorflow import silence_tensorflow\n",
    "silence_tensorflow()\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.compat.v1.Session(config = config)\n",
    "\n",
    "import os, shutil\n",
    "import json\n",
    "import subprocess\n",
    "\n",
    "from net_model import *\n",
    "from custom_model import *\n",
    "from mps_models import *\n",
    "\n",
    "import mps\n",
    "import pwexp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7234c69d-b83f-478e-a2d1-c432b3b60f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sample_mnist_rgp10 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c3838bd-3256-4d51-bac7-cdc840410d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "i_valid_train = pd.Series(train_labels).isin([0,1,2,3,4]).to_numpy()\n",
    "i_valid_test = pd.Series(test_labels).isin([0,1,2,3,4]).to_numpy()\n",
    "\n",
    "# Filters to take only the images with labels in [0, 1, 2, 3, 4]\n",
    "train_labels = train_labels[i_valid_train]\n",
    "test_labels = test_labels[i_valid_test]\n",
    "\n",
    "# Indices for each set of filtered data\n",
    "i_train = np.arange(train_labels.shape[0])\n",
    "i_test = np.arange(test_labels.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "001317f7-3f12-45fd-b826-bc25ad734d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_theta(log_a, log_phi, C, C_inv, sup, p_0, theta_min = None, theta_max = None):\n",
    "    '''\n",
    "        Given the specifications for the latent causes distribution and a vector with cure probabilities,\n",
    "        inverts the cure probability function and returns the theta parameters for each individual\n",
    "    '''\n",
    "    theta = C_inv( np.exp(log_a(0.0) - np.log(p_0)) )\n",
    "    \n",
    "    # Se theta é limitado inferiormente por um valor theta_min > 0, valores de theta obtidos abaixo do limite são levados para o limite inferior do parâmetro\n",
    "    if(theta_min is not None):\n",
    "        theta[theta <= theta_min] = theta_min + 1.0e-5\n",
    "    # Se theta é limitado superiormente por um valor theta_max > 0, valores de theta obtidos acima do limite são levados para o limite superior do parâmetro\n",
    "    if(theta_min is not None):\n",
    "        theta[theta >= theta_max] = theta_max - 1.0e-5\n",
    "        \n",
    "    return theta\n",
    "\n",
    "\n",
    "def generate_data(log_a, log_phi, theta, sup, low_c, high_c):\n",
    "    '''\n",
    "        Dada a especificação do modelo e um vetor com os parâmetros individuais, gera os tempos de vida e censuras de cada indivíduo.\n",
    "        low_c e high_c definem o intervalo para a geração dos tempos de censura, seguindo uma distribuição U[low_c, high_c]\n",
    "    '''\n",
    "    n = len(theta)\n",
    "    m = mps.rvs(log_a, log_phi, theta, sup, size = 10)\n",
    "    \n",
    "    cured = np.zeros(n)\n",
    "    delta = cured.copy()\n",
    "    t = cured.copy()\n",
    "    \n",
    "    # Censorship times\n",
    "    c = np.random.uniform(low = low_c, high = high_c, size = n)\n",
    "    \n",
    "    for i in range(n):\n",
    "        if(m[i] == 0):\n",
    "            t[i] = c[i]\n",
    "            cured[i] = 1\n",
    "        else:\n",
    "            # Risco base segue uma distribuição Exp(1)\n",
    "            z = expon.rvs(loc = 0.0, scale = 1.0, size = int(m[i]))\n",
    "            t[i] = np.min(z)\n",
    "    \n",
    "    # Atualiza as posições não censuradas para delta = 1\n",
    "    delta[t < c] = 1\n",
    "    # Os tempos censurados passam a assumir o valor do tempo de censura\n",
    "    t[t >= c] = c[t >= c]\n",
    "    \n",
    "    # Retorna os tempos, deltas e o vetor de causas latentes (que na prática é desconhecido)\n",
    "    return m, t, delta, cured\n",
    "\n",
    "def join_datasets(n_train, n_val, n_test, theta_train, theta_val, theta_test, m_train, m_val, m_test, t_train, t_val, t_test, delta_train, delta_val, delta_test):\n",
    "    sets = np.concatenate([np.repeat(\"train\", n_train), np.repeat(\"val\", n_val), np.repeat(\"test\", n_test)])\n",
    "    theta = np.concatenate([theta_train, theta_val, theta_test])\n",
    "    m = np.concatenate([m_train, m_val, m_test])\n",
    "    t = np.concatenate([t_train, t_val, t_test])\n",
    "    delta = np.concatenate([delta_train, delta_val, delta_test])\n",
    "    return pd.DataFrame({\"theta\": theta, \"m\": m, \"t\": t, \"delta\": delta, \"set\": sets})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a58f956-c612-46d6-82fa-b4bf926d0349",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_single_bootstrap_rgp10(cure_probs_dict_vec, directory, file_index):\n",
    "    '''\n",
    "        Get a single bootstrap sample from the Fashion-MNIST dataset considering each distribution from scenario 1.\n",
    "    '''\n",
    "    filename = \"data_{}.csv\".format(file_index)\n",
    "\n",
    "    # ---------------------------- Sample the indices from the original dataset ----------------------------\n",
    "    \n",
    "    df_indices = pd.read_csv(\"{}/indices_{}.csv\".format(directory, file_index))\n",
    "    indices = df_indices[\"index\"].to_numpy()\n",
    "    sets = df_indices[\"set\"].to_numpy()\n",
    "\n",
    "    # Indices for train and validation\n",
    "    i_train_val = indices[ (sets == \"train\") | (sets == \"val\") ]\n",
    "    i_test = indices[ sets == \"test\" ]\n",
    "    \n",
    "    n_train = int(np.sum(sets == \"train\"))\n",
    "    n_val = int(np.sum(sets == \"val\"))\n",
    "    n_test = int(np.sum(sets == \"test\"))\n",
    "    n = n_train + n_val + n_test\n",
    "    \n",
    "    # The labels for the train set are the first n_train sampled indices in i_train_val\n",
    "    label_train = train_labels[i_train_val[:n_train]]\n",
    "    # The labels for the validation set are the last n_train sampled indices in i_train_val\n",
    "    label_val = train_labels[i_train_val[n_train:]]\n",
    "    # Takes the labels for the test set\n",
    "    label_test = test_labels[i_test]\n",
    "    \n",
    "    p_train = cure_probs_dict_vec(label_train)\n",
    "    p_val = cure_probs_dict_vec(label_val)\n",
    "    p_test = cure_probs_dict_vec(label_test)\n",
    "\n",
    "    # The censored times follow a U(low_c, high_c) distribution - To control the censored and cured observations properly, we should have a different distribution \n",
    "    # for each of the chosen distributions for M\n",
    "    low_c = 0\n",
    "    high_c = 6\n",
    "    \n",
    "    # ---------------------------- RPG(-1/10) ----------------------------\n",
    "    q = -1.0/10.0\n",
    "    # RPG(-1/10) - Training data\n",
    "    theta_train_rgp10 = get_theta(log_a_rgp(q), log_phi_rgp(q), C_rgp(q), C_inv_rgp(q), sup_rgp(q), p_train, theta_min = theta_min_rgp, theta_max = theta_max_rgp(q))\n",
    "    m_train_rgp10, t_train_rgp10, delta_train_rgp10, cured_train_rgp10 = \\\n",
    "        generate_data(log_a_rgp(q), log_phi_rgp(q), theta_train_rgp10, sup_rgp(q), low_c, high_c)\n",
    "    # RPG(-1/10) - Validation data\n",
    "    theta_val_rgp10 = get_theta(log_a_rgp(q), log_phi_rgp(q), C_rgp(q), C_inv_rgp(q), sup_rgp(q), p_val, theta_min = theta_min_rgp, theta_max = theta_max_rgp(q))\n",
    "    m_val_rgp10, t_val_rgp10, delta_val_rgp10, cured_val_rgp10 = \\\n",
    "        generate_data(log_a_rgp(q), log_phi_rgp(q), theta_val_rgp10, sup_rgp(q), low_c, high_c)\n",
    "    # RPG(-1/10) - Test data\n",
    "    theta_test_rgp10 = get_theta(log_a_rgp(q), log_phi_rgp(q), C_rgp(q), C_inv_rgp(q), sup_rgp(q), p_test, theta_min = theta_min_rgp, theta_max = theta_max_rgp(q))\n",
    "    m_test_rgp10, t_test_rgp10, delta_test_rgp10, cured_test_rgp10 = \\\n",
    "        generate_data(log_a_rgp(q), log_phi_rgp(q), theta_test_rgp10, sup_rgp(q), low_c, high_c)\n",
    "    # Save the DataFrame with the simulated values for the RGP(-1/10)\n",
    "    rgp10_data = join_datasets(\n",
    "        n_train, n_val, n_test,\n",
    "        theta_train_rgp10, theta_val_rgp10, theta_test_rgp10,\n",
    "        m_train_rgp10, m_val_rgp10, m_test_rgp10,\n",
    "        t_train_rgp10, t_val_rgp10, t_test_rgp10,\n",
    "        delta_train_rgp10, delta_val_rgp10, delta_test_rgp10\n",
    "    )\n",
    "    # rgp10_data.to_csv(\"{}/poisson/{}\".format(directory, filename), index = False)\n",
    "    return rgp10_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6031f45d-c7ad-41b0-968c-b411566a49ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>theta</th>\n",
       "      <th>m</th>\n",
       "      <th>t</th>\n",
       "      <th>delta</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.105361</td>\n",
       "      <td>0</td>\n",
       "      <td>0.145632</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.514128</td>\n",
       "      <td>2</td>\n",
       "      <td>0.246477</td>\n",
       "      <td>1.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.105361</td>\n",
       "      <td>0</td>\n",
       "      <td>4.987943</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.966113</td>\n",
       "      <td>1</td>\n",
       "      <td>0.588371</td>\n",
       "      <td>1.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      theta  m         t  delta    set\n",
       "0  0.105361  0  0.145632    0.0  train\n",
       "1  1.514128  2  0.246477    1.0  train\n",
       "2  0.105361  0  4.987943    0.0  train\n",
       "3  1.966113  1  0.588371    1.0  train"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cure_probs_dict1 = {0: 0.9, 1:0.45, 2:0.22, 3:0.14, 4: 0.08}\n",
    "cure_probs_dict1 = np.vectorize(cure_probs_dict1.get)\n",
    "\n",
    "directory = \"SimulationDataset/Scenario1/n{}\".format(500)\n",
    "file_index = 1\n",
    "\n",
    "np.random.seed(333)\n",
    "\n",
    "df = sample_single_bootstrap_rgp10(cure_probs_dict1, directory, file_index)\n",
    "df.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d923f565-b861-45d2-a443-8480d4d2ee0f",
   "metadata": {},
   "source": [
    "# Verify Geeta(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ee718fae-7286-49b2-89e7-c2ad6440dd52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta = 0.0253205655191035\n",
      "E(M) = 0.05480414702456948\n",
      "Var(M) = 0.06255978928610026\n",
      "Xbarra = 0.057692307692307696\n",
      "sigma2 = 0.054363905325443794\n",
      "# ------------------------------- #\n",
      "theta = 0.0780455542707112\n",
      "E(M) = 0.20381065519413055\n",
      "Var(M) = 0.3203566830417516\n",
      "Xbarra = 0.1935483870967742\n",
      "sigma2 = 0.31737773152965665\n",
      "# ------------------------------- #\n",
      "theta = 0.1339745962155613\n",
      "E(M) = 0.4480184754795915\n",
      "Var(M) = 1.0847096365573436\n",
      "Xbarra = 0.41134751773049644\n",
      "sigma2 = 0.908807404054122\n",
      "# ------------------------------- #\n",
      "theta = 0.1937742251701449\n",
      "E(M) = 0.9256494863025442\n",
      "Var(M) = 4.257399084050784\n",
      "Xbarra = 0.8695652173913043\n",
      "sigma2 = 3.368079935187685\n",
      "# ------------------------------- #\n",
      "theta = 0.2583801512904337\n",
      "E(M) = 2.2981470499148755\n",
      "Var(M) = 33.70827275711524\n",
      "Xbarra = 2.537313432835821\n",
      "sigma2 = 20.03965248384941\n",
      "# ------------------------------- #\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"SimulationDataset/Scenario2/n500/geeta3/data_15.csv\")\n",
    "df.head()\n",
    "\n",
    "for theta in np.sort(df.theta.unique()):\n",
    "    df_theta = df.loc[ df.theta == theta, : ]\n",
    "    print(\"theta = {}\".format(theta))\n",
    "\n",
    "    print(\"E(M) = {}\".format( E_geeta(3, theta) ))\n",
    "    print(\"Var(M) = {}\".format( Var_geeta(3, theta) ))\n",
    "    print(\"Xbarra = {}\".format( np.mean(df_theta.m) ))\n",
    "    print(\"sigma2 = {}\".format( np.var(df_theta.m) ))\n",
    "    print(\"# ------------------------------- #\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c8dc92b8-c235-4f6a-82a2-261af426ee0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "i_valid_train = pd.Series(train_labels).isin([0,1,2,3,4]).to_numpy()\n",
    "i_valid_test = pd.Series(test_labels).isin([0,1,2,3,4]).to_numpy()\n",
    "\n",
    "# Filters to take only the images with labels in [0, 1, 2, 3, 4]\n",
    "train_images = train_images[i_valid_train]\n",
    "train_images = train_images / np.max(train_images)\n",
    "train_shape = train_images.shape\n",
    "# Adds one more dimension for keras to identify the \"colors\" dimension\n",
    "train_images = np.reshape(train_images, (train_shape[0], train_shape[1], train_shape[2], 1))\n",
    "\n",
    "test_images = test_images[i_valid_test]\n",
    "test_images = test_images / np.max(test_images)\n",
    "test_shape = test_images.shape\n",
    "# Adds one more dimension for keras to identify the \"colors\" dimension\n",
    "test_images = np.reshape(test_images, (test_shape[0], test_shape[1], test_shape[2], 1))\n",
    "\n",
    "train_labels = train_labels[i_valid_train]\n",
    "test_labels = test_labels[i_valid_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "761e6ece-0fbd-4df9-973d-127786a085b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(data_dir, file_index, distribution, train_images, test_images):\n",
    "    '''\n",
    "        Example:\n",
    "            data_dir = \"SimulationDataset/Scenario1/n500\"\n",
    "            file_index = 20\n",
    "            distribution = \"poisson\"\n",
    "    '''\n",
    "    index_path = \"{}/indices_{}.csv\".format(data_dir, file_index, distribution)\n",
    "    data_path = \"{}/{}/data_{}.csv\".format(data_dir, distribution, file_index)\n",
    "    df_index = pd.read_csv(index_path)\n",
    "    df_data = pd.read_csv(data_path)\n",
    "\n",
    "    index_train = df_index.loc[df_index.set == \"train\",\"index\"].to_numpy()\n",
    "    index_val = df_index.loc[df_index.set == \"val\",\"index\"].to_numpy()\n",
    "    index_test = df_index.loc[df_index.set == \"test\",\"index\"].to_numpy()\n",
    "\n",
    "    # Values for the thetas\n",
    "    theta_train = df_data.loc[df_data.set == \"train\", \"theta\"]\n",
    "    theta_val = df_data.loc[df_data.set == \"val\", \"theta\"]\n",
    "    theta_test = df_data.loc[df_data.set == \"test\", \"theta\"]\n",
    "    # Values for the latent variable\n",
    "    m_train = df_data.loc[df_data.set == \"train\", \"m\"]\n",
    "    m_val = df_data.loc[df_data.set == \"val\", \"m\"]\n",
    "    m_test = df_data.loc[df_data.set == \"test\", \"m\"]\n",
    "    # Values for the time variable\n",
    "    t_train = df_data.loc[df_data.set == \"train\", \"t\"]\n",
    "    t_val = df_data.loc[df_data.set == \"val\", \"t\"]\n",
    "    t_test = df_data.loc[df_data.set == \"test\", \"t\"]\n",
    "    # Values for the censorship indicators\n",
    "    delta_train = df_data.loc[df_data.set == \"train\", \"delta\"]\n",
    "    delta_val = df_data.loc[df_data.set == \"val\", \"delta\"]\n",
    "    delta_test = df_data.loc[df_data.set == \"test\", \"delta\"]\n",
    "\n",
    "    img_train = train_images[index_train,:,:]\n",
    "    img_val = train_images[index_val,:,:]\n",
    "    img_test = test_images[index_test,:,:]\n",
    "\n",
    "    result = {\n",
    "        \"theta_train\": theta_train, \"theta_val\": theta_val, \"theta_test\": theta_test,\n",
    "        \"m_train\": m_train, \"m_val\": m_val, \"m_test\": m_test,\n",
    "        \"t_train\": t_train, \"t_val\": t_val, \"t_test\": t_test,\n",
    "        \"delta_train\": delta_train, \"delta_val\": delta_val, \"delta_test\": delta_test,\n",
    "        \"img_train\": img_train, \"img_val\": img_val, \"img_test\": img_test,\n",
    "        \"index_train\": index_train, \"index_val\": index_val, \"index_test\": index_test\n",
    "    }\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "10e5d3e4-9a63-4069-802f-4f3ab206596e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_model(distribution, q):\n",
    "    if(distribution == \"poisson\"):      \n",
    "        log_a_str = log_a_poisson_str\n",
    "        log_phi_str = log_phi_poisson_str\n",
    "        C_str = C_poisson_str\n",
    "        C_inv_str = C_inv_poisson_str\n",
    "        sup_str = sup_poisson_str\n",
    "        theta_min = None\n",
    "        theta_max = None\n",
    "    elif(distribution == \"logarithmic\"):\n",
    "        log_a_str = log_a_log_str\n",
    "        log_phi_str = log_phi_log_str\n",
    "        C_str = C_log_str\n",
    "        C_inv_str = C_inv_log_str\n",
    "        sup_str = sup_log_str\n",
    "        theta_min = 0\n",
    "        theta_max = 1\n",
    "    elif(distribution == \"nb\" or distribution == \"mvnb\"):\n",
    "        if(q is None):\n",
    "            raise Exception(\"Please, specify the fixed parameter (q) for the distribution.\")\n",
    "        # In the EM.py file, we must ensure that q is of type tf.float64 for it to work properly\n",
    "        q_argument = \"tf.constant({}, dtype = tf.float64)\".format(q)\n",
    "        log_a_str = log_a_mvnb_str.format(q_argument)\n",
    "        log_phi_str = log_phi_mvnb_str.format(q_argument)\n",
    "        C_str = C_mvnb_str.format(q_argument)\n",
    "        C_inv_str = C_inv_mvnb_str.format(q_argument)\n",
    "        sup_str = sup_mvnb_str.format(q_argument)\n",
    "        theta_min = None\n",
    "        theta_max = None\n",
    "    elif(distribution == \"geometric\"):\n",
    "        # In the EM.py file, we must ensure that q is of type tf.float64 for it to work properly\n",
    "        q_argument = \"tf.constant(1, dtype = tf.float64)\"\n",
    "        log_a_str = log_a_mvnb_str.format(q_argument)\n",
    "        log_phi_str = log_phi_mvnb_str.format(q_argument)\n",
    "        C_str = C_mvnb_str.format(q_argument)\n",
    "        C_inv_str = C_inv_mvnb_str.format(q_argument)\n",
    "        sup_str = sup_mvnb_str.format(q_argument)\n",
    "        theta_min = None\n",
    "        theta_max = None\n",
    "    elif(distribution == \"binomial\"): \n",
    "        if(q is None):\n",
    "            raise Exception(\"Please, specify the fixed parameter (q) for the distribution.\")\n",
    "        # In the EM.py file, we must ensure that q is of type tf.float64 for it to work properly\n",
    "        q_argument = \"tf.constant({}, dtype = tf.float64)\".format(q)\n",
    "        log_a_str = log_a_bin_str.format(q_argument)\n",
    "        log_phi_str = log_phi_bin_str.format(q_argument)\n",
    "        C_str = C_bin_str.format(q_argument)\n",
    "        C_inv_str = C_inv_bin_str.format(q_argument)\n",
    "        sup_str = sup_bin_str.format(q_argument)\n",
    "        theta_min = 0\n",
    "        theta_max = 1\n",
    "    elif(distribution == \"bernoulli\"):\n",
    "        # In the EM.py file, we must ensure that q is of type tf.float64 for it to work properly\n",
    "        q_argument = \"tf.constant(1, dtype = tf.float64)\"\n",
    "        log_a_str = log_a_bin_str.format(q_argument)\n",
    "        log_phi_str = log_phi_bin_str.format(q_argument)\n",
    "        C_str = C_bin_str.format(q_argument)\n",
    "        C_inv_str = C_inv_bin_str.format(q_argument)\n",
    "        sup_str = sup_bin_str.format(q_argument)\n",
    "        theta_min = 0\n",
    "        theta_max = 1\n",
    "    elif(distribution == \"rgp\"):\n",
    "        if(q is None):\n",
    "            raise Exception(\"Please, specify the fixed parameter (q) for the distribution.\")\n",
    "        # In the EM.py file, we must ensure that q is of type tf.float64 for it to work properly\n",
    "        q_argument = \"tf.constant({}, dtype = tf.float64)\".format(q)\n",
    "        log_a_str = log_a_rgp_str.format(q_argument)\n",
    "        log_phi_str = log_phi_rgp_str.format(q_argument)\n",
    "        C_str = C_rgp_str.format(q_argument)\n",
    "        C_inv_str = C_inv_rgp_str.format(q_argument)\n",
    "        sup_str = sup_rgp_str.format(q_argument)\n",
    "        theta_min = 0\n",
    "        theta_max = np.abs(1/q)\n",
    "    elif(distribution == \"borel\"):\n",
    "        # In the EM.py file, we must ensure that q is of type tf.float64 for it to work properly\n",
    "        q_argument = \"tf.constant(1, dtype = tf.float64)\"\n",
    "        log_a_str = log_a_rgp_str.format(q_argument)\n",
    "        log_phi_str = log_phi_rgp_str.format(q_argument)\n",
    "        C_str = C_rgp_str.format(q_argument)\n",
    "        C_inv_str = C_inv_rgp_str.format(q_argument)\n",
    "        sup_str = sup_rgp_str.format(q_argument)\n",
    "        theta_min = 0\n",
    "        theta_max = 1\n",
    "    elif(distribution == \"geeta\"):\n",
    "        if(q is None):\n",
    "            raise Exception(\"Please, specify the fixed parameter (q) for the distribution.\")\n",
    "        # In the EM.py file, we must ensure that q is of type tf.float64 for it to work properly\n",
    "        q_argument = \"tf.constant({}, dtype = tf.float64)\".format(q)\n",
    "        log_a_str = log_a_geeta_str.format(q_argument)\n",
    "        log_phi_str = log_phi_geeta_str.format(q_argument)\n",
    "        C_str = C_geeta_str.format(q_argument)\n",
    "        C_inv_str = C_inv_geeta_str.format(q_argument)\n",
    "        sup_str = sup_geeta_str.format(q_argument)\n",
    "        theta_min = 0\n",
    "        theta_max = np.abs(1/q)\n",
    "    elif(distribution == \"haight\"):\n",
    "        # In the EM.py file, we must ensure that q is of type tf.float64 for it to work properly\n",
    "        q_argument = \"tf.constant(2, dtype = tf.float64)\"\n",
    "        log_a_str = log_a_geeta_str.format(q_argument)\n",
    "        log_phi_str = log_phi_geeta_str.format(q_argument)\n",
    "        C_str = C_geeta_str.format(q_argument)\n",
    "        C_inv_str = C_inv_geeta_str.format(q_argument)\n",
    "        sup_str = sup_geeta_str.format(q_argument)\n",
    "        theta_min = 0\n",
    "        theta_max = 1/2\n",
    "\n",
    "    return log_a_str, log_phi_str, C_str, C_inv_str, sup_str, theta_min, theta_max\n",
    "\n",
    "def fit_cure_model(distribution, q,\n",
    "                   t_train, t_val,\n",
    "                   delta_train, delta_val,\n",
    "                   img_train, img_val,\n",
    "                   max_iterations = 100,\n",
    "                   early_stopping_em = True, early_stopping_em_warmup = 5, early_stopping_em_eps = 1.0e-6,\n",
    "                   epochs = 100, batch_size = None, shuffle = True,\n",
    "                   learning_rate = 0.001, run_eagerly = False,\n",
    "                   early_stopping_nn = True, early_stopping_min_delta_nn = 0.0, early_stopping_patience_nn = 5,\n",
    "                   reduce_lr = True, reduce_lr_steps = 10, reduce_lr_factor = 0.1,\n",
    "                   verbose = 1, seed = 1):\n",
    "    alpha0, s_t = initialize_alpha_s(t_train, n_cuts = 5)\n",
    "\n",
    "    # Select the MPS functions based on the chosen distribution\n",
    "    log_a_str, log_phi_str, C_str, C_inv_str, sup_str, theta_min, theta_max = select_model(distribution, q)\n",
    "\n",
    "    set_all_seeds(seed)\n",
    "    # Because it only serves to initialize the model weights, the distribution does not matter in this case (that's why we use the Poisson here)\n",
    "    dummy_mps_model = MPScrModel(log_a_poisson_tf, log_phi_poisson_tf, C_poisson_tf, C_inv_poisson_tf, sup_poisson)\n",
    "    dummy_mps_model.define_structure(shape_input = img_train[0].shape, seed = seed)\n",
    "\n",
    "    # If batch_size is null, use just one big batch\n",
    "    if(batch_size is None):\n",
    "        batch_size = len(t_train)\n",
    "    print(\"C_str: {}\".format(C_str))\n",
    "    results = call_EM(\"EM.py\",\n",
    "                      log_a_str, log_phi_str, C_str, C_inv_str, sup_str, theta_min, theta_max,\n",
    "                      dummy_mps_model, alpha0, s_t,\n",
    "                      img_train, t_train, delta_train, delta_train,\n",
    "                      max_iterations = max_iterations,\n",
    "                      early_stopping_em = early_stopping_em, early_stopping_em_warmup = early_stopping_em_warmup, early_stopping_em_eps = early_stopping_em_eps,\n",
    "                      epochs = epochs, batch_size = batch_size, shuffle = shuffle,\n",
    "                      learning_rate = learning_rate, run_eagerly = run_eagerly,\n",
    "                      early_stopping_nn = early_stopping_nn, early_stopping_min_delta_nn = early_stopping_min_delta_nn, early_stopping_patience_nn = early_stopping_patience_nn,\n",
    "                      reduce_lr = reduce_lr, reduce_lr_steps = reduce_lr_steps, reduce_lr_factor = reduce_lr_factor,\n",
    "                      validation = True,\n",
    "                      x_val = img_val, t_val = t_val, delta_val = delta_val, m_val = delta_val,\n",
    "                      verbose = verbose, seed = seed, alpha_known = False)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7fbab778-424d-4a30-b830-20e5082a6bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys: ['theta_train', 'theta_val', 'theta_test', 'm_train', 'm_val', 'm_test', 't_train', 't_val', 't_test', 'delta_train', 'delta_val', 'delta_test', 'img_train', 'img_val', 'img_test', 'index_train', 'index_val', 'index_test']\n"
     ]
    }
   ],
   "source": [
    "file_info = load_file(\"SimulationDataset/Scenario2/n500/\", 5, \"geeta3\", train_images, test_images)\n",
    "print( \"Keys: {}\".format(list(file_info.keys())) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ae1ffa-c23f-472b-be4b-e6c9b8f7d0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_all_seeds(10)\n",
    "\n",
    "sim_results = fit_cure_model(\"geeta3\", 3,\n",
    "               file_info[\"t_train\"], file_info[\"t_val\"],\n",
    "               file_info[\"delta_train\"], file_info[\"delta_val\"],\n",
    "               file_info[\"img_train\"], file_info[\"img_val\"],\n",
    "               batch_size = None,\n",
    "               seed = 1, verbose = 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
