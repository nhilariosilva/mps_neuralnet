{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83f4eaa6-a6b8-4b2c-98b9-db8b51ed5351",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1741042659.514411   22272 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1741042659.518082   22272 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "I0000 00:00:1741042661.268977   22272 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4203 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 6GB Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "/home/natan/.pyenv/versions/3.10.16/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "\n",
    "from scipy.special import comb, loggamma, lambertw\n",
    "from scipy.stats import multinomial, expon\n",
    "\n",
    "from silence_tensorflow import silence_tensorflow\n",
    "silence_tensorflow()\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.compat.v1.Session(config = config)\n",
    "\n",
    "import os, shutil\n",
    "import json\n",
    "import subprocess\n",
    "\n",
    "from net_model import *\n",
    "from custom_model import *\n",
    "from mps_models import *\n",
    "\n",
    "import mps\n",
    "import pwexp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7234c69d-b83f-478e-a2d1-c432b3b60f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sample_mnist_rgp10 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c3838bd-3256-4d51-bac7-cdc840410d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "i_valid_train = pd.Series(train_labels).isin([0,1,2,3,4]).to_numpy()\n",
    "i_valid_test = pd.Series(test_labels).isin([0,1,2,3,4]).to_numpy()\n",
    "\n",
    "# Filters to take only the images with labels in [0, 1, 2, 3, 4]\n",
    "train_labels = train_labels[i_valid_train]\n",
    "test_labels = test_labels[i_valid_test]\n",
    "\n",
    "# Indices for each set of filtered data\n",
    "i_train = np.arange(train_labels.shape[0])\n",
    "i_test = np.arange(test_labels.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "001317f7-3f12-45fd-b826-bc25ad734d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_theta(log_a, log_phi, C, C_inv, sup, p_0, theta_min = None, theta_max = None):\n",
    "    '''\n",
    "        Given the specifications for the latent causes distribution and a vector with cure probabilities,\n",
    "        inverts the cure probability function and returns the theta parameters for each individual\n",
    "    '''\n",
    "    theta = C_inv( np.exp(log_a(0.0) - np.log(p_0)) )\n",
    "    \n",
    "    # Se theta é limitado inferiormente por um valor theta_min > 0, valores de theta obtidos abaixo do limite são levados para o limite inferior do parâmetro\n",
    "    if(theta_min is not None):\n",
    "        theta[theta <= theta_min] = theta_min + 1.0e-5\n",
    "    # Se theta é limitado superiormente por um valor theta_max > 0, valores de theta obtidos acima do limite são levados para o limite superior do parâmetro\n",
    "    if(theta_min is not None):\n",
    "        theta[theta >= theta_max] = theta_max - 1.0e-5\n",
    "        \n",
    "    return theta\n",
    "\n",
    "\n",
    "def generate_data(log_a, log_phi, theta, sup, low_c, high_c):\n",
    "    '''\n",
    "        Dada a especificação do modelo e um vetor com os parâmetros individuais, gera os tempos de vida e censuras de cada indivíduo.\n",
    "        low_c e high_c definem o intervalo para a geração dos tempos de censura, seguindo uma distribuição U[low_c, high_c]\n",
    "    '''\n",
    "    n = len(theta)\n",
    "    m = mps.rvs(log_a, log_phi, theta, sup, size = 10)\n",
    "    \n",
    "    cured = np.zeros(n)\n",
    "    delta = cured.copy()\n",
    "    t = cured.copy()\n",
    "    \n",
    "    # Censorship times\n",
    "    c = np.random.uniform(low = low_c, high = high_c, size = n)\n",
    "    \n",
    "    for i in range(n):\n",
    "        if(m[i] == 0):\n",
    "            t[i] = c[i]\n",
    "            cured[i] = 1\n",
    "        else:\n",
    "            # Risco base segue uma distribuição Exp(1)\n",
    "            z = expon.rvs(loc = 0.0, scale = 1.0, size = int(m[i]))\n",
    "            t[i] = np.min(z)\n",
    "    \n",
    "    # Atualiza as posições não censuradas para delta = 1\n",
    "    delta[t < c] = 1\n",
    "    # Os tempos censurados passam a assumir o valor do tempo de censura\n",
    "    t[t >= c] = c[t >= c]\n",
    "    \n",
    "    # Retorna os tempos, deltas e o vetor de causas latentes (que na prática é desconhecido)\n",
    "    return m, t, delta, cured\n",
    "\n",
    "def join_datasets(n_train, n_val, n_test, theta_train, theta_val, theta_test, m_train, m_val, m_test, t_train, t_val, t_test, delta_train, delta_val, delta_test):\n",
    "    sets = np.concatenate([np.repeat(\"train\", n_train), np.repeat(\"val\", n_val), np.repeat(\"test\", n_test)])\n",
    "    theta = np.concatenate([theta_train, theta_val, theta_test])\n",
    "    m = np.concatenate([m_train, m_val, m_test])\n",
    "    t = np.concatenate([t_train, t_val, t_test])\n",
    "    delta = np.concatenate([delta_train, delta_val, delta_test])\n",
    "    return pd.DataFrame({\"theta\": theta, \"m\": m, \"t\": t, \"delta\": delta, \"set\": sets})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a58f956-c612-46d6-82fa-b4bf926d0349",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_single_bootstrap_rgp10(cure_probs_dict_vec, directory, file_index):\n",
    "    '''\n",
    "        Get a single bootstrap sample from the Fashion-MNIST dataset considering each distribution from scenario 1.\n",
    "    '''\n",
    "    filename = \"data_{}.csv\".format(file_index)\n",
    "\n",
    "    # ---------------------------- Sample the indices from the original dataset ----------------------------\n",
    "    \n",
    "    df_indices = pd.read_csv(\"{}/indices_{}.csv\".format(directory, file_index))\n",
    "    indices = df_indices[\"index\"].to_numpy()\n",
    "    sets = df_indices[\"set\"].to_numpy()\n",
    "\n",
    "    # Indices for train and validation\n",
    "    i_train_val = indices[ (sets == \"train\") | (sets == \"val\") ]\n",
    "    i_test = indices[ sets == \"test\" ]\n",
    "    \n",
    "    n_train = int(np.sum(sets == \"train\"))\n",
    "    n_val = int(np.sum(sets == \"val\"))\n",
    "    n_test = int(np.sum(sets == \"test\"))\n",
    "    n = n_train + n_val + n_test\n",
    "    \n",
    "    # The labels for the train set are the first n_train sampled indices in i_train_val\n",
    "    label_train = train_labels[i_train_val[:n_train]]\n",
    "    # The labels for the validation set are the last n_train sampled indices in i_train_val\n",
    "    label_val = train_labels[i_train_val[n_train:]]\n",
    "    # Takes the labels for the test set\n",
    "    label_test = test_labels[i_test]\n",
    "    \n",
    "    p_train = cure_probs_dict_vec(label_train)\n",
    "    p_val = cure_probs_dict_vec(label_val)\n",
    "    p_test = cure_probs_dict_vec(label_test)\n",
    "\n",
    "    # The censored times follow a U(low_c, high_c) distribution - To control the censored and cured observations properly, we should have a different distribution \n",
    "    # for each of the chosen distributions for M\n",
    "    low_c = 0\n",
    "    high_c = 6\n",
    "    \n",
    "    # ---------------------------- RPG(-1/10) ----------------------------\n",
    "    q = -1.0/10.0\n",
    "    # RPG(-1/10) - Training data\n",
    "    theta_train_rgp10 = get_theta(log_a_rgp(q), log_phi_rgp(q), C_rgp(q), C_inv_rgp(q), sup_rgp(q), p_train, theta_min = theta_min_rgp, theta_max = theta_max_rgp(q))\n",
    "    m_train_rgp10, t_train_rgp10, delta_train_rgp10, cured_train_rgp10 = \\\n",
    "        generate_data(log_a_rgp(q), log_phi_rgp(q), theta_train_rgp10, sup_rgp(q), low_c, high_c)\n",
    "    # RPG(-1/10) - Validation data\n",
    "    theta_val_rgp10 = get_theta(log_a_rgp(q), log_phi_rgp(q), C_rgp(q), C_inv_rgp(q), sup_rgp(q), p_val, theta_min = theta_min_rgp, theta_max = theta_max_rgp(q))\n",
    "    m_val_rgp10, t_val_rgp10, delta_val_rgp10, cured_val_rgp10 = \\\n",
    "        generate_data(log_a_rgp(q), log_phi_rgp(q), theta_val_rgp10, sup_rgp(q), low_c, high_c)\n",
    "    # RPG(-1/10) - Test data\n",
    "    theta_test_rgp10 = get_theta(log_a_rgp(q), log_phi_rgp(q), C_rgp(q), C_inv_rgp(q), sup_rgp(q), p_test, theta_min = theta_min_rgp, theta_max = theta_max_rgp(q))\n",
    "    m_test_rgp10, t_test_rgp10, delta_test_rgp10, cured_test_rgp10 = \\\n",
    "        generate_data(log_a_rgp(q), log_phi_rgp(q), theta_test_rgp10, sup_rgp(q), low_c, high_c)\n",
    "    # Save the DataFrame with the simulated values for the RGP(-1/10)\n",
    "    rgp10_data = join_datasets(\n",
    "        n_train, n_val, n_test,\n",
    "        theta_train_rgp10, theta_val_rgp10, theta_test_rgp10,\n",
    "        m_train_rgp10, m_val_rgp10, m_test_rgp10,\n",
    "        t_train_rgp10, t_val_rgp10, t_test_rgp10,\n",
    "        delta_train_rgp10, delta_val_rgp10, delta_test_rgp10\n",
    "    )\n",
    "    # rgp10_data.to_csv(\"{}/poisson/{}\".format(directory, filename), index = False)\n",
    "    return rgp10_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6031f45d-c7ad-41b0-968c-b411566a49ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>theta</th>\n",
       "      <th>m</th>\n",
       "      <th>t</th>\n",
       "      <th>delta</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.105361</td>\n",
       "      <td>0</td>\n",
       "      <td>0.145632</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.514128</td>\n",
       "      <td>2</td>\n",
       "      <td>0.246477</td>\n",
       "      <td>1.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.105361</td>\n",
       "      <td>0</td>\n",
       "      <td>4.987943</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.966113</td>\n",
       "      <td>1</td>\n",
       "      <td>0.588371</td>\n",
       "      <td>1.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      theta  m         t  delta    set\n",
       "0  0.105361  0  0.145632    0.0  train\n",
       "1  1.514128  2  0.246477    1.0  train\n",
       "2  0.105361  0  4.987943    0.0  train\n",
       "3  1.966113  1  0.588371    1.0  train"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cure_probs_dict1 = {0: 0.9, 1:0.45, 2:0.22, 3:0.14, 4: 0.08}\n",
    "cure_probs_dict1 = np.vectorize(cure_probs_dict1.get)\n",
    "\n",
    "directory = \"SimulationDataset/Scenario1/n{}\".format(500)\n",
    "file_index = 1\n",
    "\n",
    "np.random.seed(333)\n",
    "\n",
    "df = sample_single_bootstrap_rgp10(cure_probs_dict1, directory, file_index)\n",
    "df.head(4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
