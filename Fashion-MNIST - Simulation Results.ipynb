{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8f4ca9c-f5fd-4f2d-9ced-9c7c1b5d889a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1741213943.483448 3230980 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1741213943.487049 3230980 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "I0000 00:00:1741213945.508781 3230980 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4118 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 6GB Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "/home/natan/.pyenv/versions/3.10.16/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "\n",
    "from time import time\n",
    "\n",
    "from scipy.special import comb, loggamma, lambertw\n",
    "from scipy.stats import multinomial, expon\n",
    "\n",
    "from silence_tensorflow import silence_tensorflow\n",
    "silence_tensorflow()\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.compat.v1.Session(config = config)\n",
    "\n",
    "import os, shutil\n",
    "import json\n",
    "import subprocess\n",
    "\n",
    "from net_model import *\n",
    "from custom_model import *\n",
    "from mps_models import *\n",
    "\n",
    "import mps\n",
    "import pwexp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f31a3cf7-1d2c-4533-9e80-ac950f6ae033",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "i_valid_train = pd.Series(train_labels).isin([0,1,2,3,4]).to_numpy()\n",
    "i_valid_test = pd.Series(test_labels).isin([0,1,2,3,4]).to_numpy()\n",
    "\n",
    "# Filters to take only the images with labels in [0, 1, 2, 3, 4]\n",
    "train_images = train_images[i_valid_train]\n",
    "train_images = train_images / np.max(train_images)\n",
    "train_shape = train_images.shape\n",
    "# Adds one more dimension for keras to identify the \"colors\" dimension\n",
    "train_images = np.reshape(train_images, (train_shape[0], train_shape[1], train_shape[2], 1))\n",
    "\n",
    "test_images = test_images[i_valid_test]\n",
    "test_images = test_images / np.max(test_images)\n",
    "test_shape = test_images.shape\n",
    "# Adds one more dimension for keras to identify the \"colors\" dimension\n",
    "test_images = np.reshape(test_images, (test_shape[0], test_shape[1], test_shape[2], 1))\n",
    "\n",
    "train_labels = train_labels[i_valid_train]\n",
    "test_labels = test_labels[i_valid_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811201f2-7503-4589-bf47-d86de40c59a7",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29750e4-a65b-4ab8-b21f-48b1e6b18db0",
   "metadata": {},
   "source": [
    "Now that all simulations have been performed, we will make an analysis of all the data and build the tables and graphics for the paper."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487530dd-00bf-4aba-8c59-eca562c4183c",
   "metadata": {},
   "source": [
    "# Scenario 1 - Mostly lower cure probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8818d2bb-482e-449d-ae13-a52d2604ac9e",
   "metadata": {},
   "source": [
    "In this scenario, except for model RGP(q = -1/10), all models belong to the simpler \"Power Series\" distribution. In these cases, the theoretical model allow a cure probability take values through the entire the interval $(0,1)$ (or almost, given that in the RGP(q = -1/10), it varies from $(e^{-10}, 1)$. Even though, $e^{-10} \\approx 0$). For the data generation, it was considered that each class of clothes has a different cure probability associated.\n",
    "\n",
    "In the functions below, we recalculate from scratch the values for the cure probabilities and thetas from the models in order to compare with the previous values save in files and be sure that everything is in order. In the loading function, each fitted dataset in the simulations get its real and predicted values merges to make all the evaluation metrics easier to obtain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ed75c57-bfee-4049-ab52-daae011cd881",
   "metadata": {},
   "outputs": [],
   "source": [
    "cure_probs_dict1 = {0: 0.9, 1:0.45, 2:0.22, 3:0.14, 4: 0.08}\n",
    "cure_probs_dict2 = {0: 0.95, 1:0.9, 2:0.85, 3:0.75, 4: 0.65}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "896d8cee-5993-488d-aa25-198ff61a1547",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1200 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(nrows = 1, ncols = 5, figsize = (20, 12))\n",
    "\n",
    "for i in range(5):\n",
    "    ax[i].imshow(train_images[ train_labels == i, :, : ][0])\n",
    "    ax[i].set_title(r\"Class {} - Cure $p_0 = {:.2f}$\".format(i, cure_probs_dict1[i]))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b3e174f-0305-4cbf-8861-ee382397f2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "def ROC_real(cured, pred_p):\n",
    "    fpr, tpr, thresholds = roc_curve(cured, pred_p, drop_intermediate = False)\n",
    "    return fpr, tpr, thresholds\n",
    "\n",
    "def AUC_real(cured, pred_p):\n",
    "    fpr, tpr, thresholds = ROC_real(cured, pred_p)\n",
    "    return auc(fpr, tpr)\n",
    "\n",
    "def ROC_estimated(pred_p):\n",
    "    thresholds = np.unique(pred_p)\n",
    "    # Reshape the cure_probs array for broadcasting\n",
    "    pred_p = np.reshape(pred_p, (len(pred_p), 1))\n",
    "    tpr = np.sum( (pred_p < thresholds) * (1-pred_p), axis = 0 ) / np.sum( 1-pred_p )\n",
    "    fpr = np.sum( (pred_p < thresholds) * pred_p, axis = 0 ) / np.sum( pred_p )\n",
    "    return fpr, tpr, thresholds\n",
    "\n",
    "def AUC_estimated(pred_p):\n",
    "    fpr, tpr, thresholds = ROC_estimated(pred_p)\n",
    "    return auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da2bae21-7fc8-4a20-bff8-7301d96bb3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_fitted_model(n, scenario, distribution, q, train_images, test_images, train_labels, test_labels, cure_probs_dict, file_index):\n",
    "    distribution_name = ''.join([i for i in distribution if not i.isdigit()])\n",
    "\n",
    "    # Select the functions associated to the chosen distribution model\n",
    "    log_a_str, log_phi_str, C_str, C_inv_str, sup_str, theta_min, theta_max = select_model(distribution_name, q)\n",
    "    log_a_tf = eval(log_a_str)\n",
    "    log_phi_tf = eval(log_phi_str)\n",
    "    C_tf = eval(C_str)\n",
    "    C_inv_tf = eval(C_inv_str)\n",
    "    sup_tf = eval(sup_str)\n",
    "\n",
    "    data_path = \"SimulationDataset/Scenario{}/n{}/{}\".format(scenario, n, distribution)\n",
    "    simulation_path = \"SimulationResults/Scenario{}/n{}/{}/{}\".format(scenario, n, distribution, file_index)\n",
    "    indices_img = pd.read_csv(\"SimulationDataset/Scenario{}/n{}/indices_{}.csv\".format(scenario, n, file_index))\n",
    "\n",
    "    # ----------------------- Load generated data, such as the images for the requested simulation index -----------------------\n",
    "    # Indices for the images associated to this specific sample\n",
    "    train_val_imgs_indices = indices_img[\"index\"][ (indices_img.set == \"train\") | (indices_img.set == \"val\") ].to_numpy()\n",
    "    test_imgs_indices = indices_img[\"index\"][ indices_img.set == \"test\" ].to_numpy()\n",
    "    # Join all images in a single tensor\n",
    "    train_val_imgs = train_images[train_val_imgs_indices, :, :, :]\n",
    "    test_imgs = test_images[test_imgs_indices, :, :, :]\n",
    "    imgs = np.concatenate([train_val_imgs, test_imgs])\n",
    "    data = pd.read_csv(\"{}/data_{}.csv\".format(data_path, file_index))\n",
    "    \n",
    "    # ----------------------- Load results related to the fitted simulation ----------------------- \n",
    "    fitted_model = MPScrModel(log_a_tf, log_phi_tf, C_tf, C_inv_tf, sup_tf)\n",
    "    fitted_model.define_structure(shape_input = train_images[0].shape)\n",
    "    fitted_model.load_model(\"{}/model.weights.h5\".format(simulation_path))\n",
    "    alpha_s_df = pd.read_csv(\"{}/alpha_s.csv\".format(simulation_path))\n",
    "    pred_alpha = alpha_s_df.alpha.to_numpy()\n",
    "    real_alpha = np.ones_like(pred_alpha) # Because the real latent risk distribution is Exp(1), the real alphas is the vector of ones, for any vector s_t\n",
    "    s_t = alpha_s_df.s.to_numpy()\n",
    "    data_pred = pd.read_csv(\"{}/data_pred.csv\".format(simulation_path))\n",
    "\n",
    "    # ----------------------- Join everything in a single table -----------------------\n",
    "    log_a_0 = log_a_tf(tf.constant(0.0, dtype = tf.float64))\n",
    "\n",
    "    # Obtain all the predictions made using the trained model\n",
    "    pred_eta = fitted_model.predict(imgs, verbose = 0)\n",
    "    pred_p = fitted_model.link_func( pred_eta ).numpy().flatten()\n",
    "    pred_log_p = np.log(pred_p)\n",
    "    pred_theta = C_inv_tf( np.exp( log_a_0 - pred_log_p ) ).numpy().flatten()\n",
    "\n",
    "    pred_m = update_m_mps(fitted_model, pred_alpha, s_t, imgs, data.t.to_numpy(), data.delta.to_numpy())\n",
    "    \n",
    "    # Indices where the observation is from train or validation\n",
    "    indices_train_val = indices_img[\"set\"].isin([\"train\", \"val\"])\n",
    "    indices_test = indices_img[\"set\"].isin([\"test\"])\n",
    "    labels = np.zeros( len(pred_theta) )\n",
    "    labels[ indices_train_val ] = train_labels[ indices_img.loc[ indices_train_val, \"index\" ].reset_index(drop = True) ]\n",
    "    labels[ indices_test ] = test_labels[ indices_img.loc[ indices_test, \"index\" ].reset_index(drop = True) ]\n",
    "    # Use the image labels to obtain the theoretical probabilities from the previous dictionary\n",
    "    real_p = cure_probs_dict(labels)\n",
    "    real_log_p = np.log(real_p)\n",
    "    # Using the real p acquired, obtain the real theta values too\n",
    "    real_theta = C_inv_tf( np.exp( log_a_0 - real_log_p ) )\n",
    "\n",
    "    t = data.t.to_numpy()\n",
    "    delta = data.delta.to_numpy()\n",
    "    real_S1 = S1(t, real_alpha, s_t)\n",
    "    pred_S1 = S1(t, pred_alpha, s_t)\n",
    "\n",
    "    real_Spop = Spop_known_S1(real_S1, log_a_tf, log_phi_tf, real_theta, sup_tf)\n",
    "    pred_Spop = Spop_known_S1(pred_S1, log_a_tf, log_phi_tf, pred_theta, sup_tf)\n",
    "    \n",
    "    df_summary = pd.DataFrame({\"real_theta\": real_theta, \"real_p\": real_p, \"real_m\": data.m.to_numpy(),\n",
    "                               \"pred_theta\": pred_theta, \"pred_p\": pred_p, \"pred_m\": pred_m,\n",
    "                               \"t\": t, \"delta\": delta,\n",
    "                               \"real_S1\": real_S1, \"pred_S1\": pred_S1,\n",
    "                               \"real_Spop\": real_Spop, \"pred_Spop\": pred_Spop,\n",
    "                               \"set\": indices_img[\"set\"].to_numpy()})\n",
    "    \n",
    "    return {\n",
    "        \"fit_model\": fitted_model,\n",
    "        \"pred_alpha\": pred_alpha,\n",
    "        \"pred_s_t\": s_t,\n",
    "        \"real_alpha\": real_alpha, # The real alpha vector is composed of all ones for any vector s_t - Exp(1)\n",
    "        \"imgs\": imgs,\n",
    "        \"sets\": indices_img[\"set\"].to_numpy(),\n",
    "        \"log_a\": log_a_tf,\n",
    "        \"log_phi\": log_phi_tf,\n",
    "        \"C\": C_tf,\n",
    "        \"C_inv\": C_inv_tf,\n",
    "        \"sup\": sup_tf,\n",
    "        \"summary\": df_summary\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d943250-6a6f-405c-9183-5785d32e59c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1741213954.963341 3230980 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4118 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 6GB Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1741213955.911429 3231112 service.cc:148] XLA service 0x788f78005170 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1741213955.911556 3231112 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce RTX 3050 6GB Laptop GPU, Compute Capability 8.6\n",
      "I0000 00:00:1741213955.953192 3231112 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "I0000 00:00:1741213956.480274 3231112 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>real_theta</th>\n",
       "      <th>real_p</th>\n",
       "      <th>real_m</th>\n",
       "      <th>pred_theta</th>\n",
       "      <th>pred_p</th>\n",
       "      <th>pred_m</th>\n",
       "      <th>t</th>\n",
       "      <th>delta</th>\n",
       "      <th>real_S1</th>\n",
       "      <th>pred_S1</th>\n",
       "      <th>real_Spop</th>\n",
       "      <th>pred_Spop</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.193100</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0</td>\n",
       "      <td>0.455759</td>\n",
       "      <td>0.749157</td>\n",
       "      <td>0.052606</td>\n",
       "      <td>1.130386</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.322908</td>\n",
       "      <td>0.212128</td>\n",
       "      <td>0.929283</td>\n",
       "      <td>0.787888</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.988832</td>\n",
       "      <td>0.22</td>\n",
       "      <td>18</td>\n",
       "      <td>0.985127</td>\n",
       "      <td>0.234098</td>\n",
       "      <td>13.678279</td>\n",
       "      <td>0.027132</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.973232</td>\n",
       "      <td>0.933529</td>\n",
       "      <td>0.749769</td>\n",
       "      <td>0.641801</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.193100</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0</td>\n",
       "      <td>0.273835</td>\n",
       "      <td>0.855793</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>3.769457</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023065</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.902010</td>\n",
       "      <td>0.855922</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.999205</td>\n",
       "      <td>0.14</td>\n",
       "      <td>14</td>\n",
       "      <td>0.831860</td>\n",
       "      <td>0.466561</td>\n",
       "      <td>3.630418</td>\n",
       "      <td>0.096441</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.908064</td>\n",
       "      <td>0.822583</td>\n",
       "      <td>0.367049</td>\n",
       "      <td>0.786073</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.848131</td>\n",
       "      <td>0.45</td>\n",
       "      <td>1</td>\n",
       "      <td>0.792849</td>\n",
       "      <td>0.503618</td>\n",
       "      <td>4.505854</td>\n",
       "      <td>0.022834</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.977424</td>\n",
       "      <td>0.940882</td>\n",
       "      <td>0.958642</td>\n",
       "      <td>0.925127</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>0.988832</td>\n",
       "      <td>0.22</td>\n",
       "      <td>8</td>\n",
       "      <td>0.952176</td>\n",
       "      <td>0.313193</td>\n",
       "      <td>5.236467</td>\n",
       "      <td>0.097257</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.907323</td>\n",
       "      <td>0.821358</td>\n",
       "      <td>0.557822</td>\n",
       "      <td>0.610151</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>0.988832</td>\n",
       "      <td>0.22</td>\n",
       "      <td>10</td>\n",
       "      <td>0.821674</td>\n",
       "      <td>0.476570</td>\n",
       "      <td>4.981760</td>\n",
       "      <td>0.024557</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.975742</td>\n",
       "      <td>0.937928</td>\n",
       "      <td>0.763393</td>\n",
       "      <td>0.910629</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.08</td>\n",
       "      <td>765</td>\n",
       "      <td>0.992531</td>\n",
       "      <td>0.202680</td>\n",
       "      <td>106.385111</td>\n",
       "      <td>0.000608</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999392</td>\n",
       "      <td>0.997793</td>\n",
       "      <td>0.759314</td>\n",
       "      <td>0.949571</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>0.988832</td>\n",
       "      <td>0.22</td>\n",
       "      <td>2</td>\n",
       "      <td>0.961391</td>\n",
       "      <td>0.295425</td>\n",
       "      <td>1.770995</td>\n",
       "      <td>0.693546</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.499801</td>\n",
       "      <td>0.390611</td>\n",
       "      <td>0.303435</td>\n",
       "      <td>0.370413</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>0.988832</td>\n",
       "      <td>0.22</td>\n",
       "      <td>123</td>\n",
       "      <td>0.992281</td>\n",
       "      <td>0.204004</td>\n",
       "      <td>13.672008</td>\n",
       "      <td>0.031119</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.969360</td>\n",
       "      <td>0.926759</td>\n",
       "      <td>0.730527</td>\n",
       "      <td>0.559214</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>716 rows  13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     real_theta  real_p  real_m  pred_theta    pred_p      pred_m         t  \\\n",
       "0      0.193100    0.90       0    0.455759  0.749157    0.052606  1.130386   \n",
       "1      0.988832    0.22      18    0.985127  0.234098   13.678279  0.027132   \n",
       "2      0.193100    0.90       0    0.273835  0.855793    0.000151  3.769457   \n",
       "3      0.999205    0.14      14    0.831860  0.466561    3.630418  0.096441   \n",
       "4      0.848131    0.45       1    0.792849  0.503618    4.505854  0.022834   \n",
       "..          ...     ...     ...         ...       ...         ...       ...   \n",
       "711    0.988832    0.22       8    0.952176  0.313193    5.236467  0.097257   \n",
       "712    0.988832    0.22      10    0.821674  0.476570    4.981760  0.024557   \n",
       "713    0.999996    0.08     765    0.992531  0.202680  106.385111  0.000608   \n",
       "714    0.988832    0.22       2    0.961391  0.295425    1.770995  0.693546   \n",
       "715    0.988832    0.22     123    0.992281  0.204004   13.672008  0.031119   \n",
       "\n",
       "     delta   real_S1   pred_S1  real_Spop  pred_Spop    set  \n",
       "0      0.0  0.322908  0.212128   0.929283   0.787888  train  \n",
       "1      1.0  0.973232  0.933529   0.749769   0.641801  train  \n",
       "2      0.0  0.023065  0.001100   0.902010   0.855922  train  \n",
       "3      1.0  0.908064  0.822583   0.367049   0.786073  train  \n",
       "4      1.0  0.977424  0.940882   0.958642   0.925127  train  \n",
       "..     ...       ...       ...        ...        ...    ...  \n",
       "711    1.0  0.907323  0.821358   0.557822   0.610151   test  \n",
       "712    1.0  0.975742  0.937928   0.763393   0.910629   test  \n",
       "713    1.0  0.999392  0.997793   0.759314   0.949571   test  \n",
       "714    1.0  0.499801  0.390611   0.303435   0.370413   test  \n",
       "715    1.0  0.969360  0.926759   0.730527   0.559214   test  \n",
       "\n",
       "[716 rows x 13 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = load_fitted_model(500, 1, \"logarithmic\", None, train_images, test_images, train_labels, test_labels, np.vectorize(cure_probs_dict1.get), 1)\n",
    "display( result[\"summary\"] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd6ba72-0d5a-4065-996d-caf3005e3081",
   "metadata": {},
   "source": [
    "As it can be seen above, the function obtain all the desired quantities for the calculation of the goodness-of-fit metrics used in the paper. For each simulation, we will compute these metrics and, then, take the average through every replication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49ea632e-66f7-4bca-af9f-25b29486ea1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitted_model_metrics(n, scenario, distribution, q, train_images, test_images, train_labels, test_labels, cure_probs_dict):\n",
    "\n",
    "    Spop_mean_diffs, S1_mean_diffs, p_mean_diffs, m_mean_diffs = [], [], [], []\n",
    "    auc_reals, auc_estimates = [], []\n",
    "    for i in tqdm(range(1, 101)):\n",
    "        result = load_fitted_model(n, scenario, distribution, q, train_images, test_images, train_labels, test_labels, cure_probs_dict, i)\n",
    "\n",
    "        summary = result[\"summary\"]\n",
    "        summary_test = summary.loc[ summary[\"set\"] == \"test\", : ]\n",
    "        # If there are NaNs in the dataframe, the model did not converge and must be discarded\n",
    "        if(np.any(summary_test.isna())):\n",
    "            continue\n",
    "        \n",
    "        Spop_mean_diff = np.mean( (summary_test[\"real_Spop\"] - summary_test[\"pred_Spop\"])**2 )\n",
    "        S1_mean_diff = np.mean( (summary_test[\"real_S1\"] - summary_test[\"pred_S1\"])**2 )\n",
    "        p_mean_diff = np.mean( (summary_test[\"real_p\"] - summary_test[\"pred_p\"])**2 )\n",
    "        m_mean_diff = np.mean( np.abs(summary_test[\"real_m\"] - summary_test[\"pred_m\"]) )\n",
    "        auc_real = AUC_real( (summary_test[\"real_m\"] == 0).astype(np.uint8), summary_test[\"pred_p\"] )\n",
    "        auc_estimated = AUC_estimated( summary_test[\"pred_p\"] )\n",
    "\n",
    "        Spop_mean_diffs.append(Spop_mean_diff)\n",
    "        S1_mean_diffs.append(S1_mean_diff)\n",
    "        p_mean_diffs.append(p_mean_diff)\n",
    "        m_mean_diffs.append(m_mean_diff)\n",
    "\n",
    "        auc_reals.append(auc_real)\n",
    "        auc_estimates.append(auc_estimated)\n",
    "\n",
    "    return {\n",
    "        \"Spop_mean_diffs\": np.array(Spop_mean_diffs),\n",
    "        \"S1_mean_diffs\": np.array(S1_mean_diffs),\n",
    "        \"p_mean_diffs\": np.array(p_mean_diffs),\n",
    "        \"m_mean_diffs\": np.array(m_mean_diffs),\n",
    "        \"auc_reals\": np.array(auc_reals),\n",
    "        \"auc_estimates\": np.array(auc_estimates),\n",
    "        \"delta_Spop\": np.mean(Spop_mean_diffs),\n",
    "        \"delta_S1\": np.mean(S1_mean_diffs),\n",
    "        \"delta_p\": np.mean(p_mean_diffs),\n",
    "        \"delta_m\": np.mean(m_mean_diffs),\n",
    "        \"auc_real_mean\": np.mean(auc_reals),\n",
    "        \"auc_estimate_mean\": np.mean(auc_estimates)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f7bac97-0c3a-4c9e-a46b-6dace42d9cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_metrics_distribution(scenario, distribution, q, train_images, test_images, train_labels, test_labels, cure_probs_dict):\n",
    "    metadata_500 = pd.read_csv(\"SimulationResults/Scenario{}/n{}/{}/sim_metadata.csv\".format(scenario, 500, distribution))\n",
    "    metadata_1000 = pd.read_csv(\"SimulationResults/Scenario{}/n{}/{}/sim_metadata.csv\".format(scenario, 1000, distribution))\n",
    "    metadata_3000 = pd.read_csv(\"SimulationResults/Scenario{}/n{}/{}/sim_metadata.csv\".format(scenario, 3000, distribution))\n",
    "    \n",
    "    results_500 = fitted_model_metrics(500, scenario, distribution, q, train_images, test_images, train_labels, test_labels, cure_probs_dict)\n",
    "    results_1000 = fitted_model_metrics(1000, scenario, distribution, q, train_images, test_images, train_labels, test_labels, cure_probs_dict)\n",
    "    results_3000 = fitted_model_metrics(3000, scenario, distribution, q, train_images, test_images, train_labels, test_labels, cure_probs_dict)\n",
    "\n",
    "    train_sizes = [500, 1000, 3000]\n",
    "    delta_Spop = [results_500[\"delta_Spop\"], results_1000[\"delta_Spop\"], results_3000[\"delta_Spop\"]]\n",
    "    delta_S1 = [results_500[\"delta_S1\"], results_1000[\"delta_S1\"], results_3000[\"delta_S1\"]]\n",
    "    delta_p = [results_500[\"delta_p\"], results_1000[\"delta_p\"], results_3000[\"delta_p\"]]\n",
    "    delta_m = [results_500[\"delta_m\"], results_1000[\"delta_m\"], results_3000[\"delta_m\"]]\n",
    "    average_auc_real = [results_500[\"auc_real_mean\"], results_1000[\"auc_real_mean\"], results_3000[\"auc_real_mean\"]]\n",
    "    average_auc_estimate = [results_500[\"auc_estimate_mean\"], results_1000[\"auc_estimate_mean\"], results_3000[\"auc_estimate_mean\"]]\n",
    "\n",
    "    average_exec_time = [np.mean(metadata_500[\"execution_times\"]), np.mean(metadata_1000[\"execution_times\"]), np.mean(metadata_3000[\"execution_times\"]) ]\n",
    "\n",
    "    return pd.DataFrame({\"average_execution_times\": average_exec_time, \"train_size\": train_sizes,\n",
    "                         \"delta_Spop\": delta_Spop, \"delta_S1\": delta_S1, \"delta_p\": delta_p, \"delta_m\": delta_m,\n",
    "                         \"average_auc_real\": average_auc_real, \"average_auc_estimate\": average_auc_estimate})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd30c39-9a21-4e70-8675-12b819d5cd4e",
   "metadata": {},
   "source": [
    "# Scenario 1 Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e132415-3b06-4260-8a54-1e4749faee88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results - Poisson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100/100 [01:56<00:00,  1.16s/it]\n",
      "100%|| 100/100 [03:01<00:00,  1.81s/it]\n",
      "100%|| 100/100 [07:24<00:00,  4.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results - Logarithmic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100/100 [02:01<00:00,  1.22s/it]\n",
      "100%|| 100/100 [03:07<00:00,  1.88s/it]\n",
      "100%|| 100/100 [07:28<00:00,  4.49s/it]\n"
     ]
    }
   ],
   "source": [
    "print(\"Results - Poisson\")\n",
    "poisson_metrics = model_metrics_distribution(1, \"poisson\", None, train_images, test_images, train_labels, test_labels, np.vectorize(cure_probs_dict1.get))\n",
    "poisson_metrics.to_csv(\"SimulationTables/poisson.csv\", index = False)\n",
    "print(\"Results - Logarithmic\")\n",
    "logarithmic_metrics = model_metrics_distribution(1, \"logarithmic\", None, train_images, test_images, train_labels, test_labels, np.vectorize(cure_probs_dict1.get))\n",
    "logarithmic_metrics.to_csv(\"SimulationTables/logarithmic.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9cb517f5-43d7-4fc8-9c95-fe45a266b91c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results - Geometric\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100/100 [01:56<00:00,  1.17s/it]\n",
      "100%|| 100/100 [03:04<00:00,  1.85s/it]\n",
      "100%|| 100/100 [07:16<00:00,  4.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results - Bernoulli\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100/100 [00:56<00:00,  1.78it/s]\n",
      "100%|| 100/100 [01:02<00:00,  1.60it/s]\n",
      "100%|| 100/100 [01:22<00:00,  1.21it/s]\n"
     ]
    }
   ],
   "source": [
    "print(\"Results - Geometric\")\n",
    "geometric_metrics = model_metrics_distribution(1, \"geometric\", None, train_images, test_images, train_labels, test_labels, np.vectorize(cure_probs_dict1.get))\n",
    "geometric_metrics.to_csv(\"SimulationTables/geometric.csv\", index = False)\n",
    "print(\"Results - Bernoulli\")\n",
    "bernoulli_metrics = model_metrics_distribution(1, \"bernoulli\", None, train_images, test_images, train_labels, test_labels, np.vectorize(cure_probs_dict1.get))\n",
    "bernoulli_metrics.to_csv(\"SimulationTables/bernoulli.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a608750c-45d5-432f-bc57-c030ccbc473f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results - Binomial(5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100/100 [00:56<00:00,  1.76it/s]\n",
      "100%|| 100/100 [00:59<00:00,  1.67it/s]\n",
      "100%|| 100/100 [01:26<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results - RGP(-1/10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100/100 [00:56<00:00,  1.78it/s]\n",
      "100%|| 100/100 [01:06<00:00,  1.50it/s]\n",
      "100%|| 100/100 [01:30<00:00,  1.10it/s]\n"
     ]
    }
   ],
   "source": [
    "print(\"Results - Binomial(5)\")\n",
    "bin5_metrics = model_metrics_distribution(1, \"bin5\", 5.0, train_images, test_images, train_labels, test_labels, np.vectorize(cure_probs_dict1.get))\n",
    "bin5_metrics.to_csv(\"SimulationTables/bin5.csv\", index = False)\n",
    "print(\"Results - RGP(-1/10)\")\n",
    "rgp10_metrics = model_metrics_distribution(1, \"rgp10\", -1/10, train_images, test_images, train_labels, test_labels, np.vectorize(cure_probs_dict1.get))\n",
    "rgp10_metrics.to_csv(\"SimulationTables/rgp10.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a9371ce0-196a-47d0-9130-73986e429e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results - NB(2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100/100 [02:09<00:00,  1.29s/it]\n",
      "100%|| 100/100 [03:21<00:00,  2.02s/it]\n",
      "100%|| 100/100 [08:09<00:00,  4.89s/it]\n"
     ]
    }
   ],
   "source": [
    "print(\"Results - NB(1/2)\")\n",
    "mvnb2_metrics = model_metrics_distribution(1, \"mvnb2\", 1/2, train_images, test_images, train_labels, test_labels, np.vectorize(cure_probs_dict1.get))\n",
    "mvnb2_metrics.to_csv(\"SimulationTables/mvnb2.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d1e916-3fa2-4774-88fe-ddd4bce1e075",
   "metadata": {},
   "source": [
    "# Scenario 2 Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ee5f10b-3ef8-43b2-866c-e8f60a1390b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results - Borel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100/100 [01:52<00:00,  1.12s/it]\n",
      "100%|| 100/100 [02:53<00:00,  1.74s/it]\n",
      "100%|| 100/100 [06:58<00:00,  4.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results - RPG(2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100/100 [01:51<00:00,  1.12s/it]\n",
      "100%|| 100/100 [02:50<00:00,  1.71s/it]\n",
      "100%|| 100/100 [06:44<00:00,  4.05s/it]\n"
     ]
    }
   ],
   "source": [
    "print(\"Results - Borel\")\n",
    "borel_metrics = model_metrics_distribution(2, \"borel\", None, train_images, test_images, train_labels, test_labels, np.vectorize(cure_probs_dict2.get))\n",
    "borel_metrics.to_csv(\"SimulationTables/borel.csv\", index = False)\n",
    "print(\"Results - RPG(2)\")\n",
    "logarithmic_metrics = model_metrics_distribution(2, \"rgp2\", 2.0, train_images, test_images, train_labels, test_labels, np.vectorize(cure_probs_dict2.get))\n",
    "logarithmic_metrics.to_csv(\"SimulationTables/rgp2.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35311418-07ad-4a10-be78-1c693e7c4b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results - Haight\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100/100 [01:58<00:00,  1.19s/it]\n",
      "100%|| 100/100 [03:02<00:00,  1.83s/it]\n",
      "100%|| 100/100 [07:18<00:00,  4.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results - Geeta(3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100/100 [01:58<00:00,  1.18s/it]\n",
      "100%|| 100/100 [03:02<00:00,  1.83s/it]\n",
      "100%|| 100/100 [07:16<00:00,  4.36s/it]\n"
     ]
    }
   ],
   "source": [
    "print(\"Results - Haight\")\n",
    "haight_metrics = model_metrics_distribution(2, \"haight\", None, train_images, test_images, train_labels, test_labels, np.vectorize(cure_probs_dict2.get))\n",
    "haight_metrics.to_csv(\"SimulationTables/haight.csv\", index = False)\n",
    "print(\"Results - Geeta(3)\")\n",
    "geeta3_metrics = model_metrics_distribution(2, \"geeta3\", 3.0, train_images, test_images, train_labels, test_labels, np.vectorize(cure_probs_dict2.get))\n",
    "geeta3_metrics.to_csv(\"SimulationTables/geeta3.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11e96001-9817-4440-bc0f-eda0f605a750",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_metrics_distribution(scenario, distribution, q, train_images, test_images, train_labels, test_labels, cure_probs_dict):\n",
    "    metadata_500 = pd.read_csv(\"SimulationResults/Scenario{}/n{}/{}/sim_metadata.csv\".format(scenario, 500, distribution))\n",
    "    metadata_1000 = pd.read_csv(\"SimulationResults/Scenario{}/n{}/{}/sim_metadata.csv\".format(scenario, 1000, distribution))\n",
    "    metadata_3000 = pd.read_csv(\"SimulationResults/Scenario{}/n{}/{}/sim_metadata.csv\".format(scenario, 3000, distribution))\n",
    "    \n",
    "    # results_500 = fitted_model_metrics(500, scenario, distribution, q, train_images, test_images, train_labels, test_labels, cure_probs_dict)\n",
    "    results_1000 = fitted_model_metrics(1000, scenario, distribution, q, train_images, test_images, train_labels, test_labels, cure_probs_dict)\n",
    "    results_3000 = fitted_model_metrics(3000, scenario, distribution, q, train_images, test_images, train_labels, test_labels, cure_probs_dict)\n",
    "\n",
    "    train_sizes = [1000, 3000]\n",
    "    delta_Spop = [results_1000[\"delta_Spop\"], results_3000[\"delta_Spop\"]]\n",
    "    delta_S1 = [results_1000[\"delta_S1\"], results_3000[\"delta_S1\"]]\n",
    "    delta_p = [results_1000[\"delta_p\"], results_3000[\"delta_p\"]]\n",
    "    delta_m = [results_1000[\"delta_m\"], results_3000[\"delta_m\"]]\n",
    "    average_auc_real = [results_1000[\"auc_real_mean\"], results_3000[\"auc_real_mean\"]]\n",
    "    average_auc_estimate = [results_1000[\"auc_estimate_mean\"], results_3000[\"auc_estimate_mean\"]]\n",
    "\n",
    "    average_exec_time = [np.mean(metadata_1000[\"execution_times\"]), np.mean(metadata_3000[\"execution_times\"]) ]\n",
    "\n",
    "    return pd.DataFrame({\"average_execution_times\": average_exec_time, \"train_size\": train_sizes,\n",
    "                         \"delta_Spop\": delta_Spop, \"delta_S1\": delta_S1, \"delta_p\": delta_p, \"delta_m\": delta_m,\n",
    "                         \"average_auc_real\": average_auc_real, \"average_auc_estimate\": average_auc_estimate})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1780561-895a-49c9-bdc7-d4720d2bf7d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results - Geeta(3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100/100 [03:05<00:00,  1.86s/it]\n",
      "100%|| 100/100 [07:32<00:00,  4.53s/it]\n"
     ]
    }
   ],
   "source": [
    "print(\"Results - Geeta(3)\")\n",
    "geeta3_metrics = model_metrics_distribution(2, \"geeta3\", 3.0, train_images, test_images, train_labels, test_labels, np.vectorize(cure_probs_dict2.get))\n",
    "geeta3_metrics.to_csv(\"SimulationTables/geeta3.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76882c0c-5c35-46c9-977a-46eeb86dc311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>real_theta</th>\n",
       "      <th>real_p</th>\n",
       "      <th>real_m</th>\n",
       "      <th>pred_theta</th>\n",
       "      <th>pred_p</th>\n",
       "      <th>pred_m</th>\n",
       "      <th>t</th>\n",
       "      <th>delta</th>\n",
       "      <th>real_S1</th>\n",
       "      <th>pred_S1</th>\n",
       "      <th>real_Spop</th>\n",
       "      <th>pred_Spop</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.287682</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0</td>\n",
       "      <td>0.307179</td>\n",
       "      <td>0.735519</td>\n",
       "      <td>0.000779</td>\n",
       "      <td>3.421700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.032657</td>\n",
       "      <td>0.004676</td>\n",
       "      <td>0.754017</td>\n",
       "      <td>0.736092</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.430783</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0</td>\n",
       "      <td>0.292909</td>\n",
       "      <td>0.746090</td>\n",
       "      <td>0.001887</td>\n",
       "      <td>2.499102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.082159</td>\n",
       "      <td>0.011488</td>\n",
       "      <td>0.660102</td>\n",
       "      <td>0.747494</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.597837</td>\n",
       "      <td>0.55</td>\n",
       "      <td>48</td>\n",
       "      <td>0.301335</td>\n",
       "      <td>0.739830</td>\n",
       "      <td>6.309001</td>\n",
       "      <td>0.010800</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.989258</td>\n",
       "      <td>0.983235</td>\n",
       "      <td>0.978022</td>\n",
       "      <td>0.987889</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.430783</td>\n",
       "      <td>0.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.302225</td>\n",
       "      <td>0.739172</td>\n",
       "      <td>1.317746</td>\n",
       "      <td>0.982524</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.374365</td>\n",
       "      <td>0.293820</td>\n",
       "      <td>0.704102</td>\n",
       "      <td>0.780229</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.430783</td>\n",
       "      <td>0.65</td>\n",
       "      <td>2</td>\n",
       "      <td>0.296578</td>\n",
       "      <td>0.743358</td>\n",
       "      <td>1.376816</td>\n",
       "      <td>0.855542</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.425053</td>\n",
       "      <td>0.336081</td>\n",
       "      <td>0.713505</td>\n",
       "      <td>0.791220</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>0.051293</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0</td>\n",
       "      <td>0.307520</td>\n",
       "      <td>0.735268</td>\n",
       "      <td>0.000780</td>\n",
       "      <td>3.736545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023836</td>\n",
       "      <td>0.004676</td>\n",
       "      <td>0.951051</td>\n",
       "      <td>0.735841</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>0.051293</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0</td>\n",
       "      <td>0.292738</td>\n",
       "      <td>0.746217</td>\n",
       "      <td>0.000765</td>\n",
       "      <td>4.932181</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007211</td>\n",
       "      <td>0.004676</td>\n",
       "      <td>0.950317</td>\n",
       "      <td>0.746787</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>0.051293</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0</td>\n",
       "      <td>0.308573</td>\n",
       "      <td>0.734494</td>\n",
       "      <td>0.008742</td>\n",
       "      <td>1.920932</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.146470</td>\n",
       "      <td>0.050733</td>\n",
       "      <td>0.956553</td>\n",
       "      <td>0.740832</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>0.430783</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0</td>\n",
       "      <td>0.296563</td>\n",
       "      <td>0.743369</td>\n",
       "      <td>0.104582</td>\n",
       "      <td>0.592549</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.552916</td>\n",
       "      <td>0.443937</td>\n",
       "      <td>0.740755</td>\n",
       "      <td>0.810526</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>0.162519</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0</td>\n",
       "      <td>0.289957</td>\n",
       "      <td>0.748296</td>\n",
       "      <td>0.000761</td>\n",
       "      <td>4.298227</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013593</td>\n",
       "      <td>0.004676</td>\n",
       "      <td>0.851362</td>\n",
       "      <td>0.748865</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>716 rows  13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     real_theta  real_p  real_m  pred_theta    pred_p    pred_m         t  \\\n",
       "0      0.287682    0.75       0    0.307179  0.735519  0.000779  3.421700   \n",
       "1      0.430783    0.65       0    0.292909  0.746090  0.001887  2.499102   \n",
       "2      0.597837    0.55      48    0.301335  0.739830  6.309001  0.010800   \n",
       "3      0.430783    0.65       1    0.302225  0.739172  1.317746  0.982524   \n",
       "4      0.430783    0.65       2    0.296578  0.743358  1.376816  0.855542   \n",
       "..          ...     ...     ...         ...       ...       ...       ...   \n",
       "711    0.051293    0.95       0    0.307520  0.735268  0.000780  3.736545   \n",
       "712    0.051293    0.95       0    0.292738  0.746217  0.000765  4.932181   \n",
       "713    0.051293    0.95       0    0.308573  0.734494  0.008742  1.920932   \n",
       "714    0.430783    0.65       0    0.296563  0.743369  0.104582  0.592549   \n",
       "715    0.162519    0.85       0    0.289957  0.748296  0.000761  4.298227   \n",
       "\n",
       "     delta   real_S1   pred_S1  real_Spop  pred_Spop    set  \n",
       "0      0.0  0.032657  0.004676   0.754017   0.736092  train  \n",
       "1      0.0  0.082159  0.011488   0.660102   0.747494  train  \n",
       "2      1.0  0.989258  0.983235   0.978022   0.987889  train  \n",
       "3      1.0  0.374365  0.293820   0.704102   0.780229  train  \n",
       "4      1.0  0.425053  0.336081   0.713505   0.791220  train  \n",
       "..     ...       ...       ...        ...        ...    ...  \n",
       "711    0.0  0.023836  0.004676   0.951051   0.735841   test  \n",
       "712    0.0  0.007211  0.004676   0.950317   0.746787   test  \n",
       "713    0.0  0.146470  0.050733   0.956553   0.740832   test  \n",
       "714    0.0  0.552916  0.443937   0.740755   0.810526   test  \n",
       "715    0.0  0.013593  0.004676   0.851362   0.748865   test  \n",
       "\n",
       "[716 rows x 13 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = load_fitted_model(500, 2, \"rgp2\", 2, train_images, test_images, train_labels, test_labels, np.vectorize(cure_probs_dict2.get), 1)\n",
    "display( result[\"summary\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5fb99ca8-1f26-4715-b80e-f2cc20e07166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.28768207, 0.43078292, 0.597837  , 0.16251893, 0.05129329])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"summary\"][\"real_theta\"].unique()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
