{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2cf31daa-ca4f-49b2-82b0-88b5b828d03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.special import comb, loggamma, lambertw\n",
    "from scipy.stats import multinomial, expon\n",
    "\n",
    "from silence_tensorflow import silence_tensorflow\n",
    "silence_tensorflow()\n",
    "import tensorflow as tf\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from net_model import *\n",
    "from custom_model import *\n",
    "from mps_models import *\n",
    "import mps\n",
    "import pwexp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c0b7d9-346d-47f1-b700-b767177a1ad5",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f90952d8-5cd9-4310-a545-daf47aecf4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "i_valid_train = pd.Series(train_labels).isin([0,1,2,3,4]).to_numpy()\n",
    "i_valid_test = pd.Series(test_labels).isin([0,1,2,3,4]).to_numpy()\n",
    "\n",
    "# Filters to take only the images with labels in [0, 1, 2, 3, 4]\n",
    "train_images = train_images[i_valid_train]\n",
    "test_images = test_images[i_valid_test]\n",
    "train_labels = train_labels[i_valid_train]\n",
    "test_labels = test_labels[i_valid_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af433fe-ee3d-4ab0-b8a8-3e77d78efa59",
   "metadata": {},
   "source": [
    "#### Function to read a specific simulated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4babee9-5147-4769-981f-6c8cbd3bec15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(data_dir, file_index, distribution, train_images, test_images):\n",
    "    '''\n",
    "        Example:\n",
    "            data_dir = \"SimulationDataset/Scenario1/n500\"\n",
    "            file_index = 20\n",
    "            distribution = \"poisson\"\n",
    "    '''\n",
    "    index_path = \"{}/indices_{}.csv\".format(data_dir, file_index, distribution)\n",
    "    data_path = \"{}/{}/data_{}.csv\".format(data_dir, distribution, file_index)\n",
    "    df_index = pd.read_csv(index_path)\n",
    "    df_data = pd.read_csv(data_path)\n",
    "\n",
    "    index_train = df_index.loc[df_index.set == \"train\",\"index\"].to_numpy()\n",
    "    index_val = df_index.loc[df_index.set == \"val\",\"index\"].to_numpy()\n",
    "    index_test = df_index.loc[df_index.set == \"test\",\"index\"].to_numpy()\n",
    "\n",
    "    # Values for the thetas\n",
    "    theta_train = df_data.loc[df_data.set == \"train\", \"theta\"]\n",
    "    theta_val = df_data.loc[df_data.set == \"val\", \"theta\"]\n",
    "    theta_test = df_data.loc[df_data.set == \"test\", \"theta\"]\n",
    "    # Values for the latent variable\n",
    "    m_train = df_data.loc[df_data.set == \"train\", \"m\"]\n",
    "    m_val = df_data.loc[df_data.set == \"val\", \"m\"]\n",
    "    m_test = df_data.loc[df_data.set == \"test\", \"m\"]\n",
    "    # Values for the time variable\n",
    "    t_train = df_data.loc[df_data.set == \"train\", \"t\"]\n",
    "    t_val = df_data.loc[df_data.set == \"val\", \"t\"]\n",
    "    t_test = df_data.loc[df_data.set == \"test\", \"t\"]\n",
    "    # Values for the censorship indicators\n",
    "    delta_train = df_data.loc[df_data.set == \"train\", \"delta\"]\n",
    "    delta_val = df_data.loc[df_data.set == \"val\", \"delta\"]\n",
    "    delta_test = df_data.loc[df_data.set == \"test\", \"delta\"]\n",
    "\n",
    "    img_train = train_images[index_train,:,:]\n",
    "    img_val = train_images[index_val,:,:]\n",
    "    img_test = test_images[index_test,:,:]\n",
    "\n",
    "    result = {\n",
    "        \"theta_train\": theta_train, \"theta_val\": theta_val, \"theta_test\": theta_test,\n",
    "        \"m_train\": m_train, \"m_val\": m_val, \"m_test\": m_test,\n",
    "        \"t_train\": t_train, \"t_val\": t_val, \"t_test\": t_test,\n",
    "        \"delta_train\": delta_train, \"delta_val\": delta_val, \"delta_test\": delta_test,\n",
    "        \"img_train\": img_train, \"img_val\": img_val, \"img_test\": img_test\n",
    "    }\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59cce04-a050-4299-9592-d0a50cc9f875",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha0, s_t = initialize_alpha_s(t_train, n_cuts = 5)\n",
    "s_t = np.array([0.0, 2.062, 3.36, 4.495, 6.32, 12.2])\n",
    "\n",
    "print(\"alpha0: {}\".format(alpha0))\n",
    "print(\"cuts: {}\".format(s_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08403ed-6fd9-4462-b32c-65d392178c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_simulation(log_a_str\n",
    "                    theta_train, theta_val\n",
    "                   m_train, m_val,\n",
    "                   t_train, t_val,\n",
    "                   delta_train, delta_val,\n",
    "                   img_train, img_val,\n",
    "                   distribution, seed = 1):\n",
    "    set_all_seeds(seed)\n",
    "    \n",
    "    alpha0, s_t = initialize_alpha_s(t_train, n_cuts = 5)\n",
    "\n",
    "    if(distribution == \"poisson\"):\n",
    "        model = MPScrModel(a_poisson, phi_poisson, C_poisson, C_inv_poisson, sup_poisson)\n",
    "        model.define_structure(shape_input = x_train[0].shape, seed = 42)\n",
    "    \n",
    "    results = call_EM(\"EM.py\",\n",
    "                      a_poisson_str, phi_poisson_str, C_poisson_str, C_inv_poisson_str, B_poisson_str, sup_poisson_str,\n",
    "                      poisson_model, alpha0, s_t,\n",
    "                      x_train, t_train, delta_train, delta_train,\n",
    "                      max_iterations = 60,\n",
    "                      early_stopping_em = True, early_stopping_em_warmup = 5, early_stopping_em_eps = 1.0e-6,\n",
    "                      epochs = 100, batch_size = 64, shuffle = True,\n",
    "                      learning_rate = 0.001, run_eagerly = False,\n",
    "                      early_stopping_nn = True, early_stopping_min_delta_nn = 0.0, early_stopping_patience_nn = 5,\n",
    "                      reduce_lr = True, reduce_lr_steps = 10, reduce_lr_factor = 0.1,\n",
    "                      validation = True,\n",
    "                      x_val = x_test, t_val = t_test, delta_val = delta_test, m_val = delta_test,\n",
    "                      verbose = 3, alpha_known = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3e1f5e63-8894-41db-a907-a5c5f9d34ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_file(\"SimulationDataset/Scenario1/n500\", 1, \"bernoulli\", train_images, test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65e5ed9-22fe-4686-b7d4-53d68bd00624",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d085dd69-dae7-46ae-90aa-313229890a67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([27554, 20611,  9781, 22729, 28783, 20657, 20557,  5412,  2964,\n",
       "       20330,  9120, 25574, 29502, 23313, 24980, 19122, 28657, 25458,\n",
       "       12747,  9515, 15814, 28472, 25117, 13016,  2545, 16713, 29172,\n",
       "       23178, 29868, 21933, 18044, 15748,  8345,   451, 21680,  9091,\n",
       "       21351, 10261, 27171, 25670, 13532,   834, 10912, 19098,  6653,\n",
       "       20043,  6052, 12421, 25685, 11967, 12229,  9524, 26588, 22616,\n",
       "        9897, 12354, 26131,  1757, 18501,  6840, 29865, 23657, 28265,\n",
       "        9150, 11506, 21491,  2798, 23006, 29199,   225,  2838, 15680,\n",
       "       17875, 29019,  7356, 16019, 13670, 12501,  7721, 27724, 25094,\n",
       "       10464,  3946, 20153, 23772, 28781,  6362, 20124, 25939, 29900,\n",
       "       15311, 11188,  4352, 23837, 17852, 10516, 18408,  5098,   337,\n",
       "       13914, 13394, 27472, 20384, 16831, 27251,  7862,  5439,  4738])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_file(\"SimulationDataset/Scenario1/n500\", 1, \"bernoulli\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
